import multiprocessing
import time
import argparse

from aihub_downloader import download_worker
from extractor import extract_worker
from image_transformer import transform_worker
from bucket_uploader import upload_worker

def run_pipeline(is_test=False):
    print("ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    if is_test:
        print("âš ï¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ (ë‹¤ìš´ë¡œë” ëª¨í‚¹ ì‹œ í•´ë‹¹ ë¡œì§ ì—°ë™ ê°€ëŠ¥)")
    
    # í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹  í (maxsizeë¡œ Backpressure ì œì–´)
    zip_queue = multiprocessing.Queue(maxsize=2)
    folder_queue = multiprocessing.Queue(maxsize=5)
    upload_queue = multiprocessing.Queue(maxsize=50)
    
    # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì´ˆê¸°í™”
    p_download = multiprocessing.Process(target=download_worker, args=(zip_queue,))
    p_extract = multiprocessing.Process(target=extract_worker, args=(zip_queue, folder_queue))
    p_transform = multiprocessing.Process(target=transform_worker, args=(folder_queue, upload_queue))
    p_upload = multiprocessing.Process(target=upload_worker, args=(upload_queue,))
    
    # ì†Œë¹„ì(Consumer)ë¶€í„° í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    p_upload.start()
    p_transform.start()
    p_extract.start()
    p_download.start()
    
    # ë‹¤ìš´ë¡œë”ê°€ ìì‹ ì˜ ì‘ì—…ì„ ë§ˆì¹œ í›„ Queueì— Poison Pill(None)ì„ ì „ì†¡í•˜ì—¬
    # ë’¤ì´ì€ íŒŒì´í”„ë¼ì¸ í”„ë¡œì„¸ìŠ¤ë“¤ì´ ì—°ì‡„ì ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë¨
    p_download.join()
    p_extract.join()
    p_transform.join()
    p_upload.join()
    
    print("âœ… íŒŒì´í”„ë¼ì¸ ë™ì‘ ì™„ë£Œ!")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Food Classification Data Pipeline")
    parser.add_argument("--test", action="store_true", help="Run in test mode")
    args = parser.parse_args()
    
    multiprocessing.set_start_method("spawn", force=True)
    start_time = time.time()
    run_pipeline(is_test=args.test)
    print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")

